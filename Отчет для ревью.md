# Технический отчет для code review

Дата: 24 февраля 2026  
Проект: `social-network`  
Стек: Laravel 10 + Vue 3 + Reverb + MySQL + Docker + FFmpeg

## 1. Назначение этого отчета

Этот документ предназначен для:

- технического ревью middle/senior/fullstack инженерами,
- защиты архитектурных решений на собеседовании,
- демонстрации зрелости pet-проекта как продуктовой системы.

Фокус: не на маркетинговом описании, а на инженерных решениях, рисках, компромиссах и качестве реализации.

## 2. Архитектурный контекст

Проект реализует SPA-соцсеть с модулями контента, realtime-коммуникации и мультимедиа:

- Feed (посты, комментарии, лайки, репосты),
- Realtime chat (global/direct/archive + presence + typing + reactions + attachments),
- Radio (поиск + stream proxy + избранное),
- IPTV (playlist import + proxy/transcode/relay),
- Admin panel (модерация/управление/настройки),
- RU/EN i18n и SEO.

Ключевая идея архитектуры: сохранить монолит (Laravel + SPA), но выделить доменные зоны и сервисы так, чтобы проект масштабировался без полного рефакторинга в микросервисы.

## 3. Архитектурный стиль и принципы

## 3.1 Стиль

- Backend: модульный монолит на Laravel.
- Frontend: SPA на Vue Router.
- Realtime: event-driven поверх Reverb (Pusher protocol).

## 3.2 Принципы

- Явная авторизация на уровне маршрутов и каналов.
- Валидация входа на границе (FormRequest/validate).
- Бизнес-правила в сервисах, а не в шаблонах или random-helper.
- Защита стриминговых URL от SSRF и локальных/резервных сегментов сети.
- Покрытие feature-тестами критичных пользовательских и админских сценариев.

## 3.3 Ключевые технические решения (ADR-уровень)

1. Stateful-auth через Sanctum cookie вместо JWT.
Причина: проще интеграция с web+api, CSRF-first модель, удобнее для SPA в одном домене.

2. Reverb для realtime внутри Laravel-экосистемы.
Причина: нативная интеграция broadcasting, меньше инфраструктурной сложности, чем отдельный WS backend.

3. IPTV proxy/transcode на backend.
Причина: обход CORS, повышение совместимости потоков, контроль безопасности URL.

4. Динамический storage policy (server/cloud/user choice).
Причина: продуктовая гибкость и постепенная миграция в облако без hard cutover.

## 4. Карта backend-слоев

Точки входа:

- API routes: `routes/api.php`
- Web routes + SPA fallback: `routes/web.php`
- Broadcast channels: `routes/channels.php`

Middleware/безопасность:

- `app/Http/Kernel.php`
- `app/Http/Middleware/EnsureUserIsAdmin.php`
- `app/Providers/RouteServiceProvider.php` (rate limit)
- `app/Providers/BroadcastServiceProvider.php`

Доменные контроллеры:

- Feed/User: `PostController`, `PostImageController`, `UserController`, `MediaController`
- Chat: `ChatController`
- Radio/IPTV: `RadioController`, `IptvController`
- Admin/Settings: `AdminController`, `SiteSettingController`

Сервисы:

- `PostService`
- `SiteSettingService`
- `WorldOverviewService`
- `RadioBrowserService`
- `IptvPlaylistService`
- `IptvProxyService`
- `IptvTranscodeService`

## 5. Request lifecycle (критичные цепочки)

## 5.1 Аутентификация SPA

1. Клиент получает CSRF cookie (`/sanctum/csrf-cookie`).
2. Отправляет login-запрос, сервер ставит `laravel_session`.
3. Дальнейшие API-запросы через cookie + `withCredentials`.
4. При 419 axios interceptor автообновляет CSRF cookie и повторяет запрос.

Где реализовано:

- `resources/js/bootstrap.js`
- `config/sanctum.php`
- `config/session.php`

## 5.2 Публикация поста с медиа

1. Клиент грузит файл в `/api/post_media` или `/api/post_images`.
2. `PostImageController` выбирает диск через `SiteSettingService`.
3. Создание поста `/api/posts` с `media_ids`.
4. `PostService::attachMedia` разрешает attach только owner+orphan файлов.
5. Возвращается PostResource с relation/count.

Сильная сторона: невозможность прикрепить чужой файл; это покрыто тестами безопасности.

## 5.3 Отправка сообщения в чат + realtime

1. Проверка доступа пользователя к conversation.
2. Валидация body/attachments.
3. Запись сообщения и вложений.
4. Обновление `conversation_participants.last_read_at`/unread логики.
5. Broadcast `ConversationMessageSent`.
6. Клиенты в channel получают событие и синхронизируют UI.

Где:

- `ChatController`
- `app/Events/ConversationMessageSent.php`
- `routes/channels.php`
- `resources/js/components/widgets/PersistentChatWidget.vue`

## 5.4 IPTV режимы

Direct:

- клиент играет исходный URL напрямую, минимальная нагрузка на backend.

Proxy:

- backend создает session, запрашивает upstream playlist/segments, переписывает URL, валидирует все внешние ссылки.

Transcode/Relay:

- backend стартует FFmpeg процесс, генерирует HLS playlist/segments, выдает через API, контролирует TTL и лимит сессий.

Где:

- `IptvController`
- `IptvPlaylistService`
- `IptvProxyService`
- `IptvTranscodeService`

## 6. Frontend архитектура

Инициализация:

- `resources/js/app.js` подключает i18n + router.
- `resources/views/welcome.blade.php` отдает SEO/meta/bootstrap.

Router:

- Локализованный префикс маршрутов `/:locale(ru|en)?`
- SEO canonical/hreflang/robots обновляется в `afterEach`.
- Guards на auth/guest/admin/verified сценарии.

Realtime:

- `window.Echo` инициализируется в `resources/js/bootstrap.js`.
- Auth endpoint для channels: `/api/broadcasting/auth`.

Крупные UI узлы:

- `PersistentChatWidget.vue`
- `PersistentRadioWidget.vue`
- `IptvPlayer.vue` (HLS/DASH/MPEGTS fallback, буферные профили, recovery logic)

Вывод: frontend реализован как application-shell, а не набор независимых страниц.

## 7. Доменная модель и реляционная структура

## 7.1 Основные связи

- `users 1:N posts`
- `users M:N users` через `subscriber_followings`
- `posts 1:N post_images`
- `users M:N posts` через `liked_posts`
- `posts 1:N comments` (с parent_id для тредов)
- `users M:N conversations` через `conversation_participants`
- `conversations 1:N conversation_messages`
- `messages 1:N attachments`
- `messages 1:N reactions` (уникально: message+user+emoji)
- `users 1:1 user_chat_settings`
- `users 1:N chat_archives`

## 7.2 Важные ограничения и индексы

- `liked_posts` unique (`user_id`,`post_id`)
- `post_views` unique (`post_id`,`user_id`,`viewed_on`)
- `conversation_participants` unique (`conversation_id`,`user_id`)
- `conversation_message_reactions` unique (`message_id`,`user_id`,`emoji`)
- индексы на feed/carousel/created_at и chat created_at ускоряют выборки

Практический эффект: контролируемая консистентность без сложной distributed-схемы.

## 8. Security deep dive

## 8.1 Threat model (на что проект реально защищается)

- XSS через текстовые поля и markup payload.
- IDOR на медиа/чат-вложения.
- SSRF через IPTV/Radio URL.
- Неавторизованный доступ к private broadcast channels.
- Эскалация доступа в админ API.
- CSRF race/cookie mismatch между окружениями.

## 8.2 Реализованные контрмеры

XSS:

- правило `NoUnsafeMarkup` режет HTML/script/handler/javascript:data и control chars.

IDOR:

- MediaController проверяет доступ по владельцу/публичности/админ-роли.
- Chat attachment доступ через membership conversation.

SSRF:

- `IptvPlaylistService::validateExternalUrl`:
  - только http/https,
  - запрет localhost/private/reserved,
  - проверка payload плейлиста на небезопасные URI/схемы.

Broadcast security:

- explicit authorization callbacks в `routes/channels.php`.
- direct chat дополнительно блокируется если есть active block между пользователями.

AuthZ:

- `auth:sanctum` + `verified` для основной части API.
- admin-префикс только под middleware `admin`.

CSRF/cookie isolation:

- разные `SESSION_COOKIE`/`XSRF_COOKIE` для local и docker.
- авто-refresh CSRF при 419 в axios interceptor.

Rate limiting:

- API: 60 req/min на user/ip.
- verify-notification throttle.

## 8.3 Остаточные риски (что можно усилить)

High:

- Нет явного централизованного anti-abuse слоя для тяжелых IPTV endpoints (нужны пер-route лимиты по CPU/IO).

Medium:

- Нет отдельной антивирусной проверки пользовательских файлов.
- Reverb `allowed_origins` сейчас широкие; для production лучше белый список.

Medium/Low:

- При росте трафика потребуются Redis/cache/queue и вынос long-running jobs.

## 9. Производительность и масштабирование

## 9.1 Где узкие места сегодня

- `ChatController` очень крупный, много обязанностей в одном классе.
- IPTV transcode CPU-heavy (FFmpeg) и требует контроля конкурентности.
- Модульные выборки feed/chat потенциально требуют более агрессивной кэш-стратегии при росте пользователей.

## 9.2 Что уже сделано правильно

- Ограничения на количество и TTL IPTV сессий.
- Индексы по часто используемым фильтрам и сортировкам.
- Ограничения `per_page` и range-validation в API.

## 9.3 План масштабирования (эволюционный)

Шаг 1:

- Перевести cache/session/queue на Redis.
- Ввести специализированные rate limits для heavy endpoints (`iptv/*`, `radio/stream`).

Шаг 2:

- Вынести FFmpeg-сессии в worker-контур.
- Добавить job queue для cleanup/maintenance.

Шаг 3:

- Горизонтальное масштабирование Reverb (Redis backplane).
- CDN + object storage lifecycle для медиа.

## 10. Эксплуатация и DevOps зрелость

Локально:

- `.env.example`, artisan init, vite dev.

Docker:

- `docker-compose.yml` с сервисами `app`, `web`, `websocket`, `db`, `frontend-build`.
- `docker/php/entrypoint.sh` выполняет bootstrap/migrate/check ffmpeg/storage symlink.

Production:

- отдельный `DEPLOY.md` с Nginx + PHP-FPM + Supervisor.
- отдельный supervisor-process для Reverb.

Что добавить для enterprise-уровня:

- централизованные логи и correlation-id,
- metrics (latency/error rate/WS connections/FFmpeg sessions),
- backup policy + disaster recovery runbook.

## 11. Тестовая стратегия

Факт:

- Feature-test покрытие широкое и ближе к black-box поведению API.

Ключевые suite:

- `ApiSecurityRefactorTest`
- `ChatFeatureTest`
- `BroadcastChannelsFeatureTest`
- `IptvFeatureTest`
- `RadioFeatureTest`
- `AdminPanelFeatureTest`
- `SiteSettingsAndDiscoveryFeatureTest`
- `AuthVerificationFeatureTest`

Frontend helper-тесты:

- `npm run test:js` (unit-тесты таймеров/сессионной логики радио).

Тестовый bootstrap стабилизирован:

- `tests/CreatesApplication.php` принудительно выставляет testing-env до bootstrap приложения.
- Cache/storage пути для тестов изолированы по process-token (`TEST_TOKEN`), чтобы исключить кросс-загрязнение артефактов и проблемы прав в Docker (`root` vs `www-data`).

Сильные стороны:

- проверяются права доступа и негативные кейсы,
- есть сценарии блокировок, broadcast auth, SSRF rejection,
- есть проверки edge-состояний IPTV.

Пробелы:

- нет полноценного e2e UI тестирования (Playwright/Cypress),
- ограниченный benchmark/load профиль для streaming endpoints.

## 12. Качество кода: сильные и слабые стороны

Сильные:

- Хорошая модульность по доменам.
- Реально работающие правила безопасности.
- Зрелый набор интеграционных тестов.
- Инфраструктурная воспроизводимость через Docker.

Слабые/долг:

- `ChatController` перегружен (SRP нарушается).
- Часть сложной логики могла бы быть выделена в application services/actions.
- Нужен единый стандарт ответов и error envelope для всех доменов.
